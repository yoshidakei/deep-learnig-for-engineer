{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section1: 入力層〜中間層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層は入力値を並べた層である。中間層では、入力値を重みとバイアスを用いて線型変換し、活性化関数によって非線形変換することによって出力値への変換を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：動物分類の実例を入れてみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-1.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層のデータを全結合することで中間層のデータを生成しているため、中間層のノードを増やすことでパラメータ数は膨大になることが想像できる。したがって、ニューラルネットワークの学習には必然的にデータサンプル数が多くなることが考えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：数式をPythonで書け。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-2.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：中間層の出力を定義しているコードを抜き出せ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（単層・単ユニット）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-3.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section2: 活性化関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力層で得られたデータに対して線形変換を行なった後に、活性化関数を用いて次の層への出力の大きさを決めている。活性化関数によって非線形変換を行うことでより複雑なモデルを構築することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中間層で使用される活性化関数には、ReLU関数、シグモイド関数、ステップ関数があり、特に深層学習ではReLU関数が使用されることが多い。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：線形と非線形の違いを図にかいて簡易に説明せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-4.png\" width=90%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークにおいて、ノード数を増やしたり、層を深くしたりすることで、複雑なネットワークは構築できるが、結局のところ全結合層のみでは線形なモデルしか構築できない。したがって、以下に示すように、より複雑なモデルを構築すためには、非線形な活性化関数を使用することが重要である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：該当する箇所を抜き出せ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-5.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section3: 出力層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力層では最終的に予測したい値への変換を行う。例えば分類問題の場合、出力値は各クラスに属する確率を示し、総和は1となる。出力層で使用する活性化関数はモデルの種類によって異なり、回帰問題は恒等関数、二値分類はシグモイド関数、多クラス分類はソフトマックス関数が使用される。出力層で得られた値と正解値との誤差を算出し、その誤差を元にモデルの重みの更新を行なっていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：なぜ引き算ではなく二乗するのか述べよ。1/2はどういう意味を持つか述べよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差を二乗しない場合、得られる誤差には正と負の値が含まれる。そのため、総和をとる際に絶対値を使用する必要があり、計算過程が複雑になる。そこで、誤差の二乗和を使用することで、計算を簡単にしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差関数は微分して勾配計算を行う際に使用する。そのため、微分して係数がなくなるように、あらかじめ1/2を計算式に含めている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：①〜③の数式に該当するソースコードを示し、一行ずつ処理を説明せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "①：18行目、②22行目の分子、③22行目の分母"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-6.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ソフトマックス関数は、22行目または26行目で示しているように、分母に総和の値、分子に各データの値をとることで、変換後のデータの総和が一になるように変換を行う。また、プログラムを安定させる目的で、21行目または25行目に示すように各データから全データの最大値を引いている（オーバーフロー対策）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：①〜②の数式に該当するソースコードを示し、一行ずつ処理を説明せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "①：39行目、②49行目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-7.png\" width=90%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交差エントロピーは、49行目にて計算を行なっている。ここで、対数関数は入力の値が0になると-∞となってしまうため、ごく僅かな値（ここでは、1e-7）を足して、計算が行えるようにしている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section4: 勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配降下法は、誤差を最小化するパラメータを探索するために使用する。誤差関数を各パラメータで微分し、得られた勾配の値を元にパラメータの更新を行う。更新の度合いを学習率によって調整する。学習率は大きすぎると最小値にたどり着かず発散してしまい、逆に小さすぎると収束に時間を要する。パラメータの更新式はいくつか提案されており、Momentum、AdaGrad、 Adadelta、Adamなどがよく利用されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：該当するソースコードを探してみよう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-8.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：オンライン学習とは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全てのデータを揃えた後に学習を開始するのではなく、データを集めながらパラメータの更新を行い、学習を進めていく学習方法のことである。大量のデータを必要とする深層学習では、しばしば使用される方法である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：この数式の意味を図にかいて説明せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-9.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配降下法でより良い学習モデルを構築するために、学習率εとパラメータ更新式の選択は非常に重要である。しかしながら、現在のところ全てのケースにおいて良いとされる値や更新式は定められていないため、色々試しながら決定するのが最良の策だと考えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section5: 誤差逆伝播法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "誤差逆伝播法とは、出力された誤差について出力層側から微分を行い、前の層へと伝搬していくことで各層のパラメータの勾配を解析的に計算する方法である。出力層側から微分を計算することで、不要な再帰的な計算を避けることが可能である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：既に行なった計算結果を保持しているソースコードを抽出せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力層にて誤差を計算し、その誤差を次の誤差を計算する際にも使用している。Pythonによるコーディングでは、計算過程が直感的にわかりやすいのが特徴である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-10.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-11.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認テスト：2つの空欄に該当するソースコードを探せ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-10.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-11.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_深層学習day1-12.png\" width=70%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
