{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 線形回帰モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "線形回帰モデルとは、教師あり学習手法の一つであり、入力とパラメータ（重み）の線形結合を出力するモデルである。学習データから得られる回帰直線には誤差が含まれていると仮定し、その平均二乗誤差を最小化するような回帰係数と切片を求める。平均二乗誤差の最小化は勾配が0になる点を求めることによって求め、本手法を最小二乗法という。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定：ボストンの住宅データセットを線形回帰モデルで分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "課題：部屋数が4で犯罪率が0.3の物件はいくらになるか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "部屋数（RM）と犯罪率（CRIM）を用いて住宅価格の線形回帰モデルを作成し、予測を行なったところ物件価格は4,240ドルとなった。実装した際のコードを以下に示す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_線形回帰.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非線形回帰モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非線形回帰モデルとは、基底関数と呼ばれる既知の非線形関数を用いて入力データの変換を行い、パラメータ（重み）との線形結合を出力するモデルである。よく使用される基底関数には、多項式関数、ガウス型規定関数、スプライン関数などがある。\n",
    "\n",
    "学習データに対して十分に小さな誤差が得られないモデルは未学習であると考えられる。一方で、小さな誤差は得られるが、検証データに対して誤差が大きいモデルは過学習であると考えられる。両者の対策として、前者はより表現力の高いモデルを使用すること、後者は学習データ数を増やす、不要な基底関数を削除して表現力を減らす、正則化を用いることなどが挙げられる。\n",
    "\n",
    "正則化には、L1ノルムを使用するLasso回帰とL2ノルムを使用するRidge回帰がある。Lasso回帰は、いくつかのパラメータが0になるためスパースなモデルが構築できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対象となる実装演習はなかったため、非線形回帰分析においてL1正則化（Lasso）、L2正則化（Ridge）を行なった際のalphaの値とフィッティング度合いについて考察を行なった。\n",
    "\n",
    "alphaの値を0.0001から1まで10倍刻みに変更した際のフィッティングの結果を以下に示す。その結果、 alphaの値がL1正則化は0.001以下から、 L2正則化は0.1以下から学習データによく適合することがわかった。一方で、alphaの値をさらに小さくしていくと、近似曲線の滑らかさが失われ、訓練データに過学習する傾向が確認できた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_非線形回帰_Lasso.png\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_非線形回帰_Ridge.png\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰とは、分類問題を解くための教師あり学習の一つであり、入力とパラメータ（重み）の線形結合をシグモイド関数に入力し、一方のクラス（y=1）に分類される確率を出力するモデルである。パラメータの推定には、尤度関数を最大とするパラメータを探索する最尤推定法を使用する。\n",
    "\n",
    "分類モデルの評価方法には、精度（Accuracy）がしばしば使用されるが、学習データのクラスに偏りがある場合には有効ではない。そのため、学習データに含まれる陽性クラスのうちどれくらいを正しく正答できたかを表す再現率（Recall）、学習モデルによって陽性クラスだと判定した中でどれくらいを正答できたかを表す適合率（Precision）、RecallとPrecisionの調和平均であるF値などの指標を用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定：タイタニックの乗客データを利用しロジスティック回帰モデルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "課題：年齢が30歳で男の乗客は生き残れるか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "年齢（Age）と性別（Sex）を用いて乗客が生き残れるかどうかを予測するモデルを作成した。実装した際のコードを以下に示す。生き残れる確率は約21％となり、死亡する確率の方が高いことがわかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_Logistic回帰.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主成分分析とは、線形変換後の変数の分散が最大となるような射影軸を探索し、データを次元削減するための手法である。主成分分析は、元データの分散共分散行列の固有値問題を解くことによって計算される。固有値を昇順に並べた際、k番目の固有値に対応する固有ベクトルを第k主成分という。固有値の和は元データの分散と一致し、第1主成分から第k主成分までの分散の全分散に対する割合を累積寄与率といい、情報損失量の割合を示す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "設定：乳がん検査データに対して主成分分析を利用し、2次元空間上に次元圧縮"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "課題：32次元のデータを2次元上に次元圧縮した際に、うまく判別できるかを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの前処理として不要な列を削除した後、乳がんデータ（30次元）に対して主成分分析を行なった。実装した際のコードを以下に示す。2次元上にプロットした結果から、良性（B）と悪性（M）を大まかに判別できそうなことがわかった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_PCA1.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_PCA2.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サポートベクターマシーン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "サポートベクトルマシン（SVM）は、教師あり学習手法の一つであり、2クラス分類問題の代表的な手法の一つである。SVMは訓練データがどちらのクラスに属するかを判定するための決定関数を使用し、その符号によって分類を行う。分類境界を挟んで2つのクラスがどのくらい離れているかをマージンと呼び、SVMでは大きなマージンをもつ分類境界を探索する（マージン最大化）。したがって、分類境界の決定には分類境界に最も近いデータのみが関与し、その他のデータは関与していない。分類境界に最も近いデータをサポートベクトルと呼ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMにおいて、線形分離可能を仮定した分類をハードマージンと呼ぶ。一方で、本仮定をなくし、線形分離可能ではないデータへの適用をはかった分類をソフトマージンと呼ぶ。ソフトマージンでは、マージン内に入るデータや誤分類されたデータに対する誤差変数（スラック変数）を用いて、マージンを最大化しつつ誤差を最小化するような分類境界を決定する。正則化係数Cは、誤差の抑制度合いを調整するパラメータであり、Cが大きいほどハードマージンに近づく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装演習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対象となる実装演習はなかったため、上記で使用した乳がんデータの主成分分析後の2次元データに対して、SVMによる分類を行い、正則化係数Cの違いによる分類境界について考察を行なった。実装した際のコードを以下に示す。分類境界を図示した結果から、Cの値が大きくなるほど誤分類されるデータが減り、より訓練データに適合した厳しい分類となることが確認できた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_SVM1.png\" width=90%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"実装演習_SVM2.png\" width=90%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
